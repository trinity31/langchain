{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trinity/Projects/FULLSTACK-GPT/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' A potato is a starchy vegetable that is native to South America. It is one of the most widely consumed crops in the world, and is grown for its edible tubers. Potatoes are usually boiled, baked, fried, or roasted, and can be served as a side dish, or used as a main ingredient in various dishes such as stews, soups, and casseroles. They are rich in carbohydrates, fiber'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"[INST]What is the meaning of {word}[/INST]\")\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", model_kwargs={\"mex_new_tokens\": 250})\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 20.0kB/s]\n",
      "Downloading config.json: 100%|██████████| 665/665 [00:00<00:00, 792kB/s]\n",
      "Downloading vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.51MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 893kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.03MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [00:50<00:00, 10.8MB/s] \n",
      "Downloading generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 67.8kB/s]\n",
      "Using pad_token, but it is not set yet.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" medium to large, oval potato, and you can eat it as well as potato cakes. You can see the potato in the photo below with both potato cakes and potato pancakes.\\n\\n\\nThe first place you'll like to cook your potatoes is around the\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "prompt_local = PromptTemplate.from_template(\"A {word} is a\")\n",
    "\n",
    "llm_local = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 50,\n",
    "    },\n",
    ")\n",
    "\n",
    "chain_local = prompt_local | llm_local\n",
    "\n",
    "chain_local.invoke({\n",
    "    \"word\": \"potato\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_local2 = PromptTemplate.from_template(\"You are a helpful assistant that defines words. Define this word: {word}\")\n",
    "\n",
    "llm_local2 = GPT4All(model=\"../falcon.gguf\", n_threads=8)\n",
    "\n",
    "chain_local2 = prompt_local2 | llm_local2\n",
    "\n",
    "chain_local2.invoke({\"word\": \"potato\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
